# Spark Configuration for Bakery Data Pipeline

# Iceberg Configuration
spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
spark.sql.catalog.local=org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.local.type=hadoop
spark.sql.catalog.local.warehouse=s3a://iceberg-warehouse/
spark.sql.catalog.local.io-impl=org.apache.iceberg.aws.s3.S3FileIO

# S3/MinIO Configuration
spark.hadoop.fs.s3a.endpoint=http://minio:9000
spark.hadoop.fs.s3a.access.key=minioadmin
spark.hadoop.fs.s3a.secret.key=minioadmin
spark.hadoop.fs.s3a.path.style.access=true
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.connection.ssl.enabled=false
spark.hadoop.fs.s3a.fast.upload=true
spark.hadoop.fs.s3a.block.size=134217728
spark.hadoop.fs.s3a.multipart.size=134217728

# Performance Configuration
spark.sql.adaptive.enabled=true
spark.sql.adaptive.coalescePartitions.enabled=true
spark.sql.adaptive.skewJoin.enabled=true
spark.sql.streaming.stateStore.providerClass=org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider
spark.sql.streaming.checkpointLocation=s3a://iceberg-warehouse/checkpoints/

# Memory Configuration
spark.driver.memory=2g
spark.executor.memory=2g
spark.executor.cores=2
spark.executor.instances=1

# Serialization
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.kryo.registrationRequired=false

# UI Configuration
spark.ui.enabled=true
spark.ui.port=4040 